![image](https://user-images.githubusercontent.com/113465005/226238596-cc76039e-67c2-46b6-b0bb-35d037ae66e1.png)

# 3 or 5 days POC VBD powered by: Azure Search + Azure OpenAI + Bot Framework + Langchain + Azure SQL + CosmosDB + Bing Search API
[![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/MSUSAzureAccelerators/Azure-Cognitive-Search-Azure-OpenAI-Accelerator?quickstart=1)
[![Open in VS Code Dev Containers](https://img.shields.io/static/v1?style=for-the-badge&label=Remote%20-%20Containers&message=Open&color=blue&logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/MSUSAzureAccelerators/Azure-Cognitive-Search-Azure-OpenAI-Accelerator)


## æ—¥æœ¬èªžè¨³ç‰ˆ

ã‚ãªãŸã®çµ„ç¹”ã§ã¯ã€ã•ã¾ã–ã¾ãªå ´æ‰€ã«ç‚¹åœ¨ã™ã‚‹å¤šç¨®å¤šæ§˜ãªã‚¿ã‚¤ãƒ—ã®ãƒ‡ãƒ¼ã‚¿ã‚’ç†è§£ã§ãã‚‹æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã¨ãƒžãƒ«ãƒãƒãƒ£ãƒ³ãƒãƒ«å¯¾å¿œã®ã‚¹ãƒžãƒ¼ãƒˆãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆãŒå¿…è¦ã§ã™ã€‚ã•ã‚‰ã«ã€ä¼šè©±åž‹ã®ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã¯ã€è³ªå•ã«å¯¾ã™ã‚‹å›žç­”ã‚’æä¾›ã™ã‚‹ã ã‘ã§ãªãã€ãã®å›žç­”ãŒã©ã®ã‚ˆã†ã«ã—ã¦ã€ã©ã“ã‹ã‚‰å¾—ã‚‰ã‚ŒãŸã®ã‹ã¨ã„ã†ã‚½ãƒ¼ã‚¹ã¨èª¬æ˜Žã‚‚æä¾›ã™ã‚‹èƒ½åŠ›ãŒæ±‚ã‚ã‚‰ã‚Œã¾ã™ã€‚è¨€ã„æ›ãˆã‚Œã°ã€**çµ„ç¹”å†…ã§ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆã‹ã¤ã‚»ã‚­ãƒ¥ã‚¢ãªChatGPTãŒãƒ“ã‚¸ãƒã‚¹ãƒ‡ãƒ¼ã‚¿ã«é–¢ã™ã‚‹è³ªå•ã‚’è§£é‡ˆã€ç†è§£ã€å›žç­”ã§ãã‚‹**ã‚ˆã†ã«ã—ãŸã„ã¨è€ƒãˆã¦ã„ã¾ã™ã€‚

ã“ã®POCï¼ˆãƒ—ãƒ«ãƒ¼ãƒ•ãƒ»ã‚ªãƒ–ãƒ»ã‚³ãƒ³ã‚»ãƒ—ãƒˆï¼‰ã®ç›®çš„ã¯ã€Azureã‚µãƒ¼ãƒ“ã‚¹ã‚’ä½¿ç”¨ã—ã¦æ§‹ç¯‰ã•ã‚ŒãŸGPTãƒãƒ¼ãƒãƒ£ãƒ«ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®ä¾¡å€¤ã‚’ã€ç‹¬è‡ªã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦è‡ªåˆ†è‡ªèº«ã®ç’°å¢ƒã§ç¤ºã™/è¨¼æ˜Žã™ã‚‹ã“ã¨ã§ã™ã€‚ç´å“ç‰©ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ï¼š

1. Bot Frameworkã§æ§‹ç¯‰ã•ã‚Œã€è¤‡æ•°ã®ãƒãƒ£ãƒ³ãƒãƒ«ï¼ˆWebãƒãƒ£ãƒƒãƒˆã€MS Teamsã€SMSã€Emailã€Slackãªã©ï¼‰ã«å…¬é–‹ã•ã‚ŒãŸãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰Bot API
2. æ¤œç´¢ã¨Bot UIã‚’å‚™ãˆãŸãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã®Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã€‚

ã“ã®ãƒªãƒã‚¸ãƒˆãƒªã¯ã€OpenAIãƒ™ãƒ¼ã‚¹ã®ã‚¹ãƒžãƒ¼ãƒˆæ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã®æ§‹ç¯‰æ–¹æ³•ã‚’æ®µéšŽçš„ã«æ•™ãˆã‚‹ãŸã‚ã«ä½œæˆã•ã‚Œã¾ã—ãŸã€‚å„ãƒŽãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¯äº’ã„ã«ç©ã¿é‡ã­ã‚‰ã‚Œã€æœ€çµ‚çš„ã«ã¯2ã¤ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®æ§‹ç¯‰ã«çµ‚ã‚ã‚Šã¾ã™ã€‚

**ãƒžã‚¤ã‚¯ãƒ­ã‚½ãƒ•ãƒˆã®FTEï¼ˆãƒ•ãƒ«ã‚¿ã‚¤ãƒ é›‡ç”¨è€…ï¼‰å‘ã‘ï¼š** ã“ã‚Œã¯é¡§å®¢ãŒè³‡é‡‘æä¾›ã™ã‚‹VBDï¼ˆValue-Based Deliveryï¼‰ã§ã‚ã‚Šã€ä»¥ä¸‹ã¯ç´å“ã®ãŸã‚ã®è³‡ç”£ã§ã™ã€‚

| **ã‚¢ã‚¤ãƒ†ãƒ **                   | **èª¬æ˜Ž**                                                                                                       | **ãƒªãƒ³ã‚¯**                                                                                                                                                |
|----------------------------|--------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------|
| VBD SKUæƒ…å ±ã¨ãƒ‡ãƒ¼ã‚¿ã‚·ãƒ¼ãƒˆ      | CSAMã¯ã“ã‚Œã‚’"Customer Invested"ã¨ã—ã¦Unified Support Contractã®ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆ/æ™‚é–“ã«å¯¾ã—ã¦ãƒ‡ã‚£ã‚¹ãƒ‘ãƒƒãƒã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚é¡§å®¢ãŒ3æ—¥ã‹5æ—¥ã‚’é¸ã³ã¾ã™ã€‚  | [ESXP SKU ãƒšãƒ¼ã‚¸](https://esxp.microsoft.com/#/omexplanding/services/14486/geo/USA/details/1)                                                         |
| VBD CSAèªå®š                  | CSAãŒãƒ¯ãƒ¼ã‚¯ã‚·ãƒ§ãƒƒãƒ—ã‚’æä¾›ã™ã‚‹ãŸã‚ã«å¿…è¦ãªèªå®šã‚’å–å¾—ã™ã‚‹ãƒªãƒ³ã‚¯                                                                                 | [ãƒªãƒ³ã‚¯ 1](https://learningplayer.microsoft.com/activity/s9261799/launch), [ãƒªãƒ³ã‚¯ 2](https://learningplayer.microsoft.com/activity/s9264662/launch)   |
| VBD 3-5æ—¥ POCè³‡ç”£ (IP)       | æä¾›ã•ã‚Œã‚‹ã¹ãMVPï¼ˆã“ã®GitHubãƒªãƒã‚¸ãƒˆãƒªï¼‰                                                                                                     | [Azure-Cognitive-Search-Azure-OpenAI-Accelerator](https://github.com/MSUSAzureAccelerators/Azure-Cognitive-Search-Azure-OpenAI-Accelerator)             |
| VBD ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ§ãƒƒãƒ—ãƒ‡ãƒƒã‚­      | ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ§ãƒƒãƒ—ã‚’ç´¹ä»‹ã—èª¬æ˜Žã™ã‚‹ã‚¹ãƒ©ã‚¤ãƒ‰ãƒ‡ãƒƒã‚­                                                                                                  | [Intro AOAI GPT Azure Smart Search Engine Accelerator.pptx](https://github.com/MSUSAzureAccelerators/Azure-Cognitive-Search-Azure-OpenAI-Accelerator/blob/main/Intro%20AOAI%20GPT%20Azure%20Smart%20Search%20Engine%20Accelerator.pptx) |
| CSAãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ“ãƒ‡ã‚ª         | ãƒžã‚¤ã‚¯ãƒ­ã‚½ãƒ•ãƒˆã®CSAå‘ã‘ã®2æ™‚é–“ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°                                                                                                  | [POC VBD ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°éŒ²ç”»](https://microsoft-my.sharepoint.com/:v:/p/jheseltine/EbxoBjWHJ-NJsnAM3qWXvVQBTK28SW7hgIrn7KaAJ77yaA?e=abiunn)       |

---

**3-5æ—¥é–“POCã®å‰ææ¡ä»¶ï¼ˆã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå‘ã‘ï¼‰**

* Azureã‚µãƒ–ã‚¹ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³
* Azure Open AIã¸ã®æ‰¿èªæ¸ˆã¿ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã€GPT-4ã‚’å«ã‚€ã€‚ã‚‚ã—é¡§å®¢ãŒGPT-4ã®æ‰¿èªã‚’æŒã£ã¦ã„ãªã„å ´åˆã€Microsoftã®CSAãŒãƒ¯ãƒ¼ã‚¯ã‚·ãƒ§ãƒƒãƒ—ä¸­ã«è²¸ã—å‡ºã™ã“ã¨ãŒã§ãã¾ã™
* ã§ãã‚Œã°ã€Microsoftã®ãƒ¡ãƒ³ãƒãƒ¼ã‚’ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®Azure ADã«ã‚²ã‚¹ãƒˆã¨ã—ã¦è¿½åŠ ã—ã¦ãã ã•ã„ã€‚ã‚‚ã—ä¸å¯èƒ½ãªå ´åˆã€é¡§å®¢ã¯Microsoftã®ãƒ¡ãƒ³ãƒãƒ¼ã«ä¼æ¥­IDã‚’ç™ºè¡Œã§ãã¾ã™
* ã“ã®ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ§ãƒƒãƒ—POCã®ãŸã‚ã«ã€é¡§å®¢ã®Azureãƒ†ãƒŠãƒ³ãƒˆå†…ã§ãƒªã‚½ãƒ¼ã‚¹ã‚°ãƒ«ãƒ¼ãƒ—ï¼ˆRGï¼‰ã‚’è¨­å®šã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™
* é¡§å®¢ãƒãƒ¼ãƒ ã¨Microsoftãƒãƒ¼ãƒ ã¯ã€ã“ã®ãƒªã‚½ãƒ¼ã‚¹ã‚°ãƒ«ãƒ¼ãƒ—ã«å¯¾ã—ã¦ã€ŒContributorã€ã®æ¨©é™ã‚’æŒã¤å¿…è¦ãŒã‚ã‚Šã€ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ§ãƒƒãƒ—ã®2é€±é–“å‰ã¾ã§ã«ã™ã¹ã¦ã‚’è¨­å®šã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™
* RGå†…ã§ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’è¨­å®šã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™
* é¡§å®¢ã®ãƒ‡ãƒ¼ã‚¿/ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯ã€ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ§ãƒƒãƒ—ã®æ—¥ç¨‹ã®å°‘ãªãã¨ã‚‚2é€±é–“å‰ã«ã€blobã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™
* ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ§ãƒƒãƒ—ä¸­ã®IDEã®å”åŠ›ã¨æ¨™æº–åŒ–ã®ãŸã‚ã«ã€AMLã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒˆã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã¨Jupyter LabãŒä½¿ç”¨ã•ã‚Œã¾ã™ã€‚ã“ã‚Œã«ã¯ã€RGå†…ã«Azure Machine Learning WorkspaceãŒãƒ‡ãƒ—ãƒ­ã‚¤ã•ã‚Œã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™
  * æ³¨ï¼šAzure Machine Learningãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹ã§ååˆ†ãªã‚³ã‚¢ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒˆã®ã‚¯ã‚©ãƒ¼ã‚¿ãŒã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„

---
# Architecture 
![Architecture](./images/GPT-Smart-Search-Architecture.jpg "Architecture")

## Flow
1. The user asks a question.
2. In the app, an OpenAI GPT-4 LLM uses a clever prompt to determine which source to use based on the user input
3. Four types of sources are available:
   * 3a. Azure SQL Database - contains COVID-related statistics in the US.
   * 3b. Azure Bing Search API - provides access to the internet allowing scenerios like: QnA on public websites .
   * 3c. Azure Cognitive Search - contains AI-enriched documents from Blob Storage (10k PDFs and 90k articles).
      * 3c.1. Uses OpenAI to vectorize the top K document chunks
      * 3c.2. Fills up the vector-based indexes on-demand.
      * 3c.3. Gets the Top N Chunks by doing a vector search on vector-based indexes.
   * 3d. CSV Tabular File - contains COVID-related statistics in the US.
4. The app retrieves the result from the source and crafts the answer.
5. The tuple (Question and Answer) is saved to CosmosDB to keep a record of the interaction and further analysis.
6. The answer is delivered to the user.

---
## Demo

https://gptsmartsearch.azurewebsites.net/

To open the Bot in MS Teams, click [HERE](https://teams.microsoft.com/l/chat/0/0?users=28:5d583679-8196-4673-9d77-c294c010bca5)

---

## ðŸ”§**Features**

   - Uses [Bot Framework](https://dev.botframework.com/) and [Bot Service](https://azure.microsoft.com/en-us/products/bot-services/) to Host the Bot API Backend and to expose it to multiple channels including MS Teams.
   - 100% Python.
   - Uses [Azure Cognitive Services](https://azure.microsoft.com/en-us/products/cognitive-services/) to index and enrich unstructured documents: Detect Language, OCR images, Key-phrases extraction, entity recognition (persons, emails, addresses, organizations, urls).
   - Uses Vector Search Capabilities of Azure Cognitive Search to provide the best semantic answer.
   - Creates vectors on-demand as users interact with the system. (versus vectorizing the whole datalake at the beginning)
   - Uses [LangChain](https://langchain.readthedocs.io/en/latest/) as a wrapper for interacting with Azure OpenAI , vector stores, constructing prompts and creating agents.
   - Multi-Lingual (ingests, indexes and understand any language)
   - Multi-Index -> multiple search indexes
   - Tabular Data Q&A with CSV files and SQL flavor Databases
   - Uses [Azure AI Document Intelligence SDK (former Form Recognizer)](https://learn.microsoft.com/en-us/azure/ai-services/document-intelligence/overview?view=doc-intel-3.0.0) to parse complex/large PDF documents
   - Uses [Bing Search API](https://www.microsoft.com/en-us/bing/apis) to power internet searches and Q&A over public websites.
   - Uses CosmosDB as persistent memory to save user's conversations.
   - Uses [Streamlit](https://streamlit.io/) to build the Frontend web application in python.
   

---

## **Steps to Run the POC/Accelerator**

Note: (Pre-requisite) You need to have an Azure OpenAI service already created

1. Fork this repo to your Github account.
2. In Azure OpenAI studio, deploy these models: **Make sure that the deployment name is the same as the model name.**
   - "gpt-35-turbo"
   - "gpt-35-turbo-16k"
   - "gpt-4"
   - "gpt-4-32k"
   - "text-embedding-ada-002"
3. Create a Resource Group where all the assets of this accelerator are going to be. Azure OpenAI can be in different RG or a different Subscription.
4. ClICK BELOW to create all the Azure Infrastructure needed to run the Notebooks (Azure Cognitive Search, Cognitive Services, etc):

[![Deploy To Azure](https://aka.ms/deploytoazurebutton)](https://portal.azure.com/#create/Microsoft.Template/uri/https%3A%2F%2Fraw.githubusercontent.com%2Fpablomarin%2FGPT-Azure-Search-Engine%2Fmain%2Fazuredeploy.json) 

**Note**: If you have never created a `Cognitive services Multi-Service account` before, please create one manually in the azure portal to read and accept the Responsible AI terms. Once this is deployed, delete this and then use the above deployment button.

5. Clone your Forked repo to your AML Compute Instance. If your repo is private, see below in Troubleshooting section how to clone a private repo.

6. Make sure you run the notebooks on a **Python 3.10 conda enviroment**
7. Install the dependencies on your machine (make sure you do the below pip comand on the same conda environment that you are going to run the notebooks. For example, in AZML compute instance run:
```
conda activate azureml_py310_sdkv2
pip install -r ./common/requirements.txt
```

You might get some pip dependancies errors, but that is ok, the libraries were installed correctly regardless of the error.

8. Edit the file `credentials.env` with your own values from the services created in step 4.
9. **Run the Notebooks in order**. They build up on top of each other.

---

<details>

<summary>FAQs</summary>
  
## **FAQs**

1. **Why use Azure Cognitive Search engine to provide the context for the LLM and not fine tune the LLM instead?**

A: Quoting the [OpenAI documentation](https://platform.openai.com/docs/guides/fine-tuning): "GPT-3 has been pre-trained on a vast amount of text from the open internet. When given a prompt with just a few examples, it can often intuit what task you are trying to perform and generate a plausible completion. This is often called "few-shot learning.
Fine-tuning improves on few-shot learning by training on many more examples than can fit in the prompt, letting you achieve better results on a wide number of tasks. Once a model has been fine-tuned, you won't need to provide examples in the prompt anymore. This **saves costs and enables lower-latency requests**"

However, fine-tuning the model requires providing hundreds or thousands of Prompt and Completion tuples, which are essentially query-response samples. The purpose of fine-tuning is not to give the LLM knowledge of the company's data but to provide it with examples so it can perform tasks really well without requiring examples on every prompt.

There are cases where fine-tuning is necessary, such as when the examples contain proprietary data that should not be exposed in prompts or when the language used is highly specialized, as in healthcare, pharmacy, or other industries or use cases where the language used is not commonly found on the internet.
</details>

<details>

<summary>Troubleshooting</summary>
  
## Troubleshooting

Steps to clone a private repo:
- On your Terminal, Paste the text below, substituting in your GitHub email address. [Generate a new SSH key](https://docs.github.com/en/authentication/connecting-to-github-with-ssh/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent#generating-a-new-ssh-key).
```bash
ssh-keygen -t ed25519 -C "your_email@example.com"
```
- Copy the SSH public key to your clipboard. [Add a new SSH key](https://docs.github.com/en/authentication/connecting-to-github-with-ssh/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent#generating-a-new-ssh-key).
```bash
cat ~/.ssh/id_ed25519.pub
# Then select and copy the contents of the id_ed25519.pub file
# displayed in the terminal to your clipboard
```
- On GitHub, go to **Settings-> SSH and GPG Keys-> New SSH Key**
- In the "Title" field, add a descriptive label for the new key. "AML Compute". In the "Key" field, paste your public key.
- Clone your private repo
```bash
git clone git@github.com:YOUR-USERNAME/YOUR-REPOSITORY.git
```
</details>

# Disclaimer: The attached diagrams and sample code are provided AS IS without warranty of any kind, and should not be interpreted as an offer or commitment on the part of Microsoft, and Microsoft cannot guarantee the accuracy of any information presented. MICROSOFT MAKES NO WARRANTIES, EXPRESS OR IMPLIED, IN THIS CODE SAMPLE.

